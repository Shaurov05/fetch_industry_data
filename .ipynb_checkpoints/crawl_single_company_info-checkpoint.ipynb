{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import date, datetime\n",
    "import json\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import re\n",
    "from time import sleep\n",
    "# driver = webdriver.Chrome()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data of company_index.json file in a list\n",
    "\n",
    "with open('company_index.json') as json_file:\n",
    "    company_list = json.load(json_file)\n",
    "\n",
    "company_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "# this function collects various information of a company\n",
    "def get_company_profile_info(company_url, company_name, info_collection_completed, driver):\n",
    "    attempt=0\n",
    "    company_info_dict = {}\n",
    "    contact_details = None\n",
    "    fetch_url_again = False\n",
    "    \n",
    "    while True:\n",
    "        attempt += 1\n",
    "            \n",
    "        try:\n",
    "            sleep(3)\n",
    "            \n",
    "            company_profile = driver.find_elements_by_class_name('CompanyTopInfo_leftContentWrap__3gIch')\n",
    "            company_details = driver.find_elements_by_class_name('CompanyTopInfo_contentWrapper__2Jkic')\n",
    "            \n",
    "            # if the page is not loaded properly, get the page again.\n",
    "            if not company_details or not company_profile:\n",
    "                fetch_url_again = True\n",
    "                break\n",
    "            \n",
    "            # if company details section is found, then start collecting informations\n",
    "            # update the dictionary company_info_dict by the collected values\n",
    "            if company_details:\n",
    "                for detail in company_details:\n",
    "                    spans = detail.find_elements_by_tag_name(\"span\")\n",
    "\n",
    "                    if spans[0].text == \"Revenue\":\n",
    "                        company_revenue = spans[1].text\n",
    "                        company_info_dict.update({ \n",
    "                            \"company_revenue\": company_revenue\n",
    "                        })\n",
    "                    elif spans[0].text == \"Head Count\":\n",
    "                        company_employee_size = spans[1].text\n",
    "                        company_info_dict.update({ \n",
    "                            \"company_employee_size\": company_employee_size\n",
    "                        })\n",
    "                    elif spans[0].text == \"Industry\":\n",
    "                        company_industry = spans[1].text\n",
    "                        company_info_dict.update({\n",
    "                            \"company_industry\": company_industry\n",
    "                        })\n",
    "                    elif spans[0].text == \"Location\":\n",
    "                        location = spans[1].text\n",
    "                        company_info_dict.update({\n",
    "                            \"company_location\": location\n",
    "                        })\n",
    "            \n",
    "            # if company profile section is found, then start collecting informations\n",
    "            if company_profile:            \n",
    "                try:\n",
    "                    company_website = company_profile[0].find_elements_by_class_name('CompanyTopInfo_websiteUrl__13kpn')[0].text\n",
    "                    company_webdomain = urlparse(company_website).netloc.replace(\"www.\", \"\")\n",
    "                except:\n",
    "                    company_website = None\n",
    "                    company_webdomain = None\n",
    "                \n",
    "                # collect the contact information by calling the function get_contact_details()\n",
    "                if contact_details == None:\n",
    "                    contact_details = get_contact_details(company_url, company_name, info_collection_completed, driver)\n",
    "                \n",
    "                # insert information in a dictionary\n",
    "                company_info_dict.update({ \n",
    "                    \"company_name\": company_profile[0].find_elements_by_tag_name('h1')[0].text,\n",
    "                    \"company_website\": company_website,\n",
    "                    \"company_webdomain\": company_webdomain,\n",
    "\n",
    "                    \"contact_details\": contact_details,\n",
    "                })\n",
    "                \n",
    "                # check if the crawler collected the required information or not\n",
    "                if len(company_info_dict) == 8:\n",
    "                    break\n",
    "                else:\n",
    "                    raise Exception(\"Could not find 8 diff values of company_info_dict\")\n",
    "                \n",
    "        except Exception as exc:\n",
    "            print(\"exception for company_profile_info: \", exc)\n",
    "            print(\"name: {}, Url: {}, attempt: {}, total completed: {}\".format(\n",
    "                                            company_name, company_url, attempt,\n",
    "                                            info_collection_completed))\n",
    "            \n",
    "            # If every required info is not collected, then again try to collect those info after \n",
    "            # refreshing the page, and stop collecting info after the 2nd attempt to collect required info\n",
    "            if attempt == 2:\n",
    "                driver.refresh()\n",
    "            elif attempt > 2:\n",
    "                break\n",
    "    \n",
    "    return company_info_dict, fetch_url_again\n",
    "\n",
    "# get_company_profile_info(\"example\", \"example\", 50, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function collects the contact information from the details page of a company\n",
    "\n",
    "def get_contact_details(company_url, company_name, info_collection_completed, driver):\n",
    "    attempt = 0\n",
    "    contact_details_list = []\n",
    "    contact_details = driver.find_elements_by_class_name('TopContacts_roundedBorder__1a3yB')\n",
    "    \n",
    "    # if contact details is present in the page, start collecting information\n",
    "    if contact_details:\n",
    "        for contact in contact_details:\n",
    "            contact_dict = {}\n",
    "            \n",
    "            while True:\n",
    "                sleep(3)\n",
    "                contact_name = contact.find_elements_by_class_name(\"TopContacts_contactName__3N-_e\")[0].text,\n",
    "                contact_jobtitle = contact.find_elements_by_class_name(\"TopContacts_jobTitle__3M7A2\")[0].text,\n",
    "                contact_email_domain = contact.find_elements_by_class_name(\"emailBtn\")[0].text.split(\"@\")[1],\n",
    "                contact_profile_link = contact.find_elements_by_tag_name(\"a\")[0].get_attribute('href'),\n",
    "                \n",
    "                # insert information in a dictionary\n",
    "                contact_dict = {\n",
    "                    \"contact_name\": [contact_name[0] if contact_name else None][0],\n",
    "                    \"contact_jobtitle\": [contact_jobtitle[0] if contact_jobtitle else None][0],\n",
    "                    \"contact_email_domain\": [contact_email_domain[0] if contact_email_domain else None][0],\n",
    "                    \"contact_profile_link\": [contact_profile_link[0] if contact_profile_link else None][0],\n",
    "                }\n",
    "\n",
    "                # contact location and contact department is not present in the details page of a \n",
    "                # company. So, we need to get the details page of each 9 contacts present on each \n",
    "                # page to collect the missing information\n",
    "                contact_link = contact.find_elements_by_tag_name(\"a\")[0].get_attribute('href')\n",
    "                contact_driver = webdriver.Chrome()\n",
    "                contact_page = contact_driver.get(contact_link)\n",
    "                \n",
    "                try:\n",
    "                    while True:\n",
    "                        attempt_to_get_contact_details = 0\n",
    "                        \n",
    "                        contact_block = contact_driver.find_elements_by_class_name('ContactTopInfo_contactDetailItem__2lk1x')\n",
    "                        contact_details = contact_block[0].find_elements_by_class_name(\"ContactTopInfo_contentWrapper__3VEQ2\")\n",
    "\n",
    "                        # update the dictionary contact_dict with the department and location info\n",
    "                        for elements in contact_details:\n",
    "                            spans = elements.find_elements_by_tag_name(\"span\")\n",
    "\n",
    "                            if spans[0].text == \"Department\":\n",
    "                                department = spans[1].text\n",
    "                                contact_dict.update({\n",
    "                                    \"contact_department\": department,\n",
    "                                })\n",
    "                            elif spans[0].text == \"Location\":\n",
    "                                location = spans[1].text\n",
    "                                contact_dict.update({\n",
    "                                    \"contact_location\": location,\n",
    "                                })\n",
    "\n",
    "                        # check if the crawler collected the required information or not\n",
    "                        if len(contact_dict) == 6:\n",
    "                            contact_driver.close()\n",
    "                            break\n",
    "                        else:\n",
    "                            attempt_to_get_contact_details += 1\n",
    "                            \n",
    "                            # if the required info is not found, try 3 times to collect the info\n",
    "                            # and after the 3rd try, stop looking for information\n",
    "                            if attempt_to_get_contact_details > 3:                                \n",
    "                                contact_driver.close()\n",
    "                                break\n",
    "                            else:\n",
    "                                continue\n",
    "                    \n",
    "                    # append the information into the list\n",
    "                    contact_details_list.append(contact_dict)\n",
    "                    break\n",
    "                    \n",
    "                except Exception as exc:\n",
    "                    print(\"exception for contact_details: \", exc)\n",
    "                    print(\"name: {}, Url: {}, attempt: {}, total completed: {}\".format(\n",
    "                                                    company_name, company_url, attempt,\n",
    "                                                    info_collection_completed))\n",
    "                    attempt += 1\n",
    "                    contact_driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    \n",
    "                    # If this is the 2nd attempt to find the info, then refresh the page and\n",
    "                    # search for the missing info again\n",
    "                    if attempt == 2:\n",
    "                        contact_driver.refresh()\n",
    "\n",
    "                if attempt > 2:\n",
    "                    # If this is the 3rd attempt to find the info, then refresh the page\n",
    "                    contact_driver.close()\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "        # return the list\n",
    "        return contact_details_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_profiles = []\n",
    "info_collection_completed = 4237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start getting the details page of each company and call the get_company_profile_info function\n",
    "# to collect required information\n",
    "\n",
    "for company in company_list[4240:]:\n",
    "    \n",
    "    attempt_to_crawl = 0\n",
    "    fetching_same_url_again = 0\n",
    "    company_url = company['source_url']\n",
    "    company_name = company['company_name']\n",
    "        \n",
    "    while True:\n",
    "        try:\n",
    "            driver = webdriver.Chrome()\n",
    "            page = driver.get(company_url)\n",
    "\n",
    "            company_profile, fetch_url_again = get_company_profile_info(company_url, company_name, \n",
    "                                                       info_collection_completed, driver)\n",
    "            \n",
    "            # if the attempt to load the page is less than 3 times, then again get the page using selenium\n",
    "            if fetch_url_again and fetching_same_url_again < 3:\n",
    "                driver.close()\n",
    "                fetching_same_url_again += 1\n",
    "                continue\n",
    "            else:   \n",
    "                # If the page is not loaded properly after 3 attempts,\n",
    "                # then close the window and look for the next url\n",
    "                company_profiles.append(company_profile)\n",
    "\n",
    "            driver.close()\n",
    "            break\n",
    "        \n",
    "        except Exception as exc:\n",
    "            print(\"exception of main function: \", exc)\n",
    "            print(\"name: {}, Url: {}, total completed: {}\".format(company_name, company_url, info_collection_completed))\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            \n",
    "            # increase the attempt_to_crawl by 1\n",
    "            attempt_to_crawl += 1\n",
    "            # if the attemp to get the page is greater than 2 times, stop searching for info\n",
    "            # for that url\n",
    "            if attempt_to_crawl > 2:\n",
    "                print(\"Could not find data for - \", company_name)\n",
    "                break\n",
    "                \n",
    "            continue\n",
    "            \n",
    "    info_collection_completed +=1\n",
    "    \n",
    "    if (info_collection_completed % 100) == 0:\n",
    "        print(\"\\n***    collected information of {} companies   ***\\n\".format(info_collection_completed))\n",
    "\n",
    "\n",
    "company_profiles[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(company_profiles)\n",
    "# company_profiles[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to add to JSON \n",
    "def write_json(data, filename='company_profiles.json'): \n",
    "    with open(filename,'w') as f: \n",
    "        json.dump(data, f, indent=4) \n",
    "      \n",
    "write_json(company_profiles) \n",
    "\n",
    "print(\"fetched information of {} companies\".format(len(company_profiles)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
